{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06311216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "322dbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs/'\n",
    "\n",
    "response = requests.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11572687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e902bc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2067428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://realpython.github.io/fake-jobs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d386a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d1928d",
   "metadata": {},
   "source": [
    "a. Use the .find method to find the tag containing the first job title (\"Senior Python Developer\"). Hint: can you find a tag type and/or a class that could be helpful for extracting this information? Extract the text from this title.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97cf79f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Python Developer\n"
     ]
    }
   ],
   "source": [
    "senior_python_dev = soup.find('h2', attrs={'class' : 'title'}).text\n",
    "print(senior_python_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45561073",
   "metadata": {},
   "source": [
    "b. Now, use what you did for the first title, but extract the job title for all jobs on this page. Store the results in a list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40de6422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Senior Python Developer', 'Energy engineer', 'Legal executive', 'Fitness centre manager', 'Product manager', 'Medical technical officer', 'Physiological scientist', 'Textile designer', 'Television floor manager', 'Waste management officer', 'Software Engineer (Python)', 'Interpreter', 'Architect', 'Meteorologist', 'Audiological scientist', 'English as a second language teacher', 'Surgeon', 'Equities trader', 'Newspaper journalist', 'Materials engineer', 'Python Programmer (Entry-Level)', 'Product/process development scientist', 'Scientist, research (maths)', 'Ecologist', 'Materials engineer', 'Historic buildings inspector/conservation officer', 'Data scientist', 'Psychiatrist', 'Structural engineer', 'Immigration officer', 'Python Programmer (Entry-Level)', 'Neurosurgeon', 'Broadcast engineer', 'Make', 'Nurse, adult', 'Air broker', 'Editor, film/video', 'Production assistant, radio', 'Engineer, communications', 'Sales executive', 'Software Developer (Python)', 'Futures trader', 'Tour manager', 'Cytogeneticist', 'Designer, multimedia', 'Trade union research officer', 'Chemist, analytical', 'Programmer, multimedia', 'Engineer, broadcasting (operations)', 'Teacher, primary school', 'Python Developer', 'Manufacturing systems engineer', 'Producer, television/film/video', 'Scientist, forensic', 'Bonds trader', 'Editorial assistant', 'Photographer', 'Retail banker', 'Jewellery designer', 'Ophthalmologist', 'Back-End Web Developer (Python, Django)', 'Licensed conveyancer', 'Futures trader', 'Counselling psychologist', 'Insurance underwriter', 'Engineer, automotive', 'Producer, radio', 'Dispensing optician', 'Designer, fashion/clothing', 'Chartered loss adjuster', 'Back-End Web Developer (Python, Django)', 'Forest/woodland manager', 'Clinical cytogeneticist', 'Print production planner', 'Systems developer', 'Graphic designer', 'Writer', 'Field seismologist', 'Chief Strategy Officer', 'Air cabin crew', 'Python Programmer (Entry-Level)', 'Warden/ranger', 'Sports therapist', 'Arts development officer', 'Printmaker', 'Health and safety adviser', 'Manufacturing systems engineer', 'Programmer, applications', 'Medical physicist', 'Media planner', 'Software Developer (Python)', 'Surveyor, land/geomatics', 'Legal executive', 'Librarian, academic', 'Barrister', 'Museum/gallery exhibitions officer', 'Radiographer, diagnostic', 'Database administrator', 'Furniture designer', 'Ship broker']\n"
     ]
    }
   ],
   "source": [
    "jobs = soup.findAll('h2', attrs={'class' : 'title'})\n",
    "\n",
    "jobs = [jobs.text for jobs in jobs]\n",
    "\n",
    "print(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567909e",
   "metadata": {},
   "source": [
    "c. Finally, extract the companies, locations, and posting dates for each job. For example, the first job has a company of \"Payne, Roberts and Davis\", a location of \"Stewartbury, AA\", and a posting date of \"2021-04-08\". Ensure that the text that you extract is clean, meaning no extra spaces or other characters at the beginning or end.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e18e6db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<h3 class=\"subtitle is-6 company\">Payne, Roberts and Davis</h3>, <h3 class=\"subtitle is-6 company\">Vasquez-Davidson</h3>, <h3 class=\"subtitle is-6 company\">Jackson, Chambers and Levy</h3>, <h3 class=\"subtitle is-6 company\">Savage-Bradley</h3>, <h3 class=\"subtitle is-6 company\">Ramirez Inc</h3>, <h3 class=\"subtitle is-6 company\">Rogers-Yates</h3>, <h3 class=\"subtitle is-6 company\">Kramer-Klein</h3>, <h3 class=\"subtitle is-6 company\">Meyers-Johnson</h3>, <h3 class=\"subtitle is-6 company\">Hughes-Williams</h3>, <h3 class=\"subtitle is-6 company\">Jones, Williams and Villa</h3>, <h3 class=\"subtitle is-6 company\">Garcia PLC</h3>, <h3 class=\"subtitle is-6 company\">Gregory and Sons</h3>, <h3 class=\"subtitle is-6 company\">Clark, Garcia and Sosa</h3>, <h3 class=\"subtitle is-6 company\">Bush PLC</h3>, <h3 class=\"subtitle is-6 company\">Salazar-Meyers</h3>, <h3 class=\"subtitle is-6 company\">Parker, Murphy and Brooks</h3>, <h3 class=\"subtitle is-6 company\">Cruz-Brown</h3>, <h3 class=\"subtitle is-6 company\">Macdonald-Ferguson</h3>, <h3 class=\"subtitle is-6 company\">Williams, Peterson and Rojas</h3>, <h3 class=\"subtitle is-6 company\">Smith and Sons</h3>, <h3 class=\"subtitle is-6 company\">Moss, Duncan and Allen</h3>, <h3 class=\"subtitle is-6 company\">Gomez-Carroll</h3>, <h3 class=\"subtitle is-6 company\">Manning, Welch and Herring</h3>, <h3 class=\"subtitle is-6 company\">Lee, Gutierrez and Brown</h3>, <h3 class=\"subtitle is-6 company\">Davis, Serrano and Cook</h3>, <h3 class=\"subtitle is-6 company\">Smith LLC</h3>, <h3 class=\"subtitle is-6 company\">Thomas Group</h3>, <h3 class=\"subtitle is-6 company\">Silva-King</h3>, <h3 class=\"subtitle is-6 company\">Pierce-Long</h3>, <h3 class=\"subtitle is-6 company\">Walker-Simpson</h3>, <h3 class=\"subtitle is-6 company\">Cooper and Sons</h3>, <h3 class=\"subtitle is-6 company\">Donovan, Gonzalez and Figueroa</h3>, <h3 class=\"subtitle is-6 company\">Morgan, Butler and Bennett</h3>, <h3 class=\"subtitle is-6 company\">Snyder-Lee</h3>, <h3 class=\"subtitle is-6 company\">Harris PLC</h3>, <h3 class=\"subtitle is-6 company\">Washington PLC</h3>, <h3 class=\"subtitle is-6 company\">Brown, Price and Campbell</h3>, <h3 class=\"subtitle is-6 company\">Mcgee PLC</h3>, <h3 class=\"subtitle is-6 company\">Dixon Inc</h3>, <h3 class=\"subtitle is-6 company\">Thompson, Sheppard and Ward</h3>, <h3 class=\"subtitle is-6 company\">Adams-Brewer</h3>, <h3 class=\"subtitle is-6 company\">Schneider-Brady</h3>, <h3 class=\"subtitle is-6 company\">Gonzales-Frank</h3>, <h3 class=\"subtitle is-6 company\">Smith-Wong</h3>, <h3 class=\"subtitle is-6 company\">Pierce-Herrera</h3>, <h3 class=\"subtitle is-6 company\">Aguilar, Rivera and Quinn</h3>, <h3 class=\"subtitle is-6 company\">Lowe, Barnes and Thomas</h3>, <h3 class=\"subtitle is-6 company\">Lewis, Gonzalez and Vasquez</h3>, <h3 class=\"subtitle is-6 company\">Taylor PLC</h3>, <h3 class=\"subtitle is-6 company\">Oliver, Jones and Ramirez</h3>, <h3 class=\"subtitle is-6 company\">Rivera and Sons</h3>, <h3 class=\"subtitle is-6 company\">Garcia PLC</h3>, <h3 class=\"subtitle is-6 company\">Johnson, Wells and Kramer</h3>, <h3 class=\"subtitle is-6 company\">Gonzalez LLC</h3>, <h3 class=\"subtitle is-6 company\">Morgan, White and Macdonald</h3>, <h3 class=\"subtitle is-6 company\">Robinson-Fitzpatrick</h3>, <h3 class=\"subtitle is-6 company\">Waters, Wilson and Hoover</h3>, <h3 class=\"subtitle is-6 company\">Hill LLC</h3>, <h3 class=\"subtitle is-6 company\">Li-Gregory</h3>, <h3 class=\"subtitle is-6 company\">Fisher, Ryan and Coleman</h3>, <h3 class=\"subtitle is-6 company\">Stewart-Alexander</h3>, <h3 class=\"subtitle is-6 company\">Abbott and Sons</h3>, <h3 class=\"subtitle is-6 company\">Bryant, Santana and Davenport</h3>, <h3 class=\"subtitle is-6 company\">Smith PLC</h3>, <h3 class=\"subtitle is-6 company\">Patterson-Singh</h3>, <h3 class=\"subtitle is-6 company\">Martinez-Berry</h3>, <h3 class=\"subtitle is-6 company\">May, Taylor and Fisher</h3>, <h3 class=\"subtitle is-6 company\">Bailey, Owen and Thompson</h3>, <h3 class=\"subtitle is-6 company\">Vasquez Ltd</h3>, <h3 class=\"subtitle is-6 company\">Leblanc LLC</h3>, <h3 class=\"subtitle is-6 company\">Jackson, Ali and Mckee</h3>, <h3 class=\"subtitle is-6 company\">Blankenship, Knight and Powell</h3>, <h3 class=\"subtitle is-6 company\">Patton, Haynes and Jones</h3>, <h3 class=\"subtitle is-6 company\">Wood Inc</h3>, <h3 class=\"subtitle is-6 company\">Collins Group</h3>, <h3 class=\"subtitle is-6 company\">Flores-Nelson</h3>, <h3 class=\"subtitle is-6 company\">Mitchell, Jones and Olson</h3>, <h3 class=\"subtitle is-6 company\">Howard Group</h3>, <h3 class=\"subtitle is-6 company\">Kramer-Edwards</h3>, <h3 class=\"subtitle is-6 company\">Berry-Houston</h3>, <h3 class=\"subtitle is-6 company\">Mathews Inc</h3>, <h3 class=\"subtitle is-6 company\">Riley-Johnson</h3>, <h3 class=\"subtitle is-6 company\">Spencer and Sons</h3>, <h3 class=\"subtitle is-6 company\">Camacho-Sanchez</h3>, <h3 class=\"subtitle is-6 company\">Oliver and Sons</h3>, <h3 class=\"subtitle is-6 company\">Eaton PLC</h3>, <h3 class=\"subtitle is-6 company\">Stanley-Frederick</h3>, <h3 class=\"subtitle is-6 company\">Bradley LLC</h3>, <h3 class=\"subtitle is-6 company\">Parker, Goodwin and Zavala</h3>, <h3 class=\"subtitle is-6 company\">Kim-Miles</h3>, <h3 class=\"subtitle is-6 company\">Moreno-Rodriguez</h3>, <h3 class=\"subtitle is-6 company\">Brown-Ortiz</h3>, <h3 class=\"subtitle is-6 company\">Hartman PLC</h3>, <h3 class=\"subtitle is-6 company\">Brooks Inc</h3>, <h3 class=\"subtitle is-6 company\">Washington-Castillo</h3>, <h3 class=\"subtitle is-6 company\">Nguyen, Yoder and Petty</h3>, <h3 class=\"subtitle is-6 company\">Holder LLC</h3>, <h3 class=\"subtitle is-6 company\">Yates-Ferguson</h3>, <h3 class=\"subtitle is-6 company\">Ortega-Lawrence</h3>, <h3 class=\"subtitle is-6 company\">Fuentes, Walls and Castro</h3>]\n"
     ]
    }
   ],
   "source": [
    "companies = soup.findAll('h3', attrs={'class' : 'company'})\n",
    "print(companies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ef7078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"location\">\n",
      "        Stewartbury, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Christopherville, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Ericaburgh, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        East Seanview, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        North Jamieview, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Davidville, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        South Christopher, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Jonathan, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Osbornetown, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Scotttown, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Ericberg, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Ramireztown, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Figueroaview, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Kelseystad, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Williamsburgh, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Mitchellburgh, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        West Jessicabury, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Maloneshire, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Johnsonton, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        South Davidtown, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Sara, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Marktown, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Laurenland, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Lauraton, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        South Tammyberg, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        North Brandonville, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Robertfurt, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Burnettbury, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Herbertside, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Christopherport, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        West Victor, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Aaron, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Loribury, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Angelastad, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Larrytown, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        West Colin, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        West Stephanie, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Laurentown, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Wrightberg, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Alberttown, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Brockburgh, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        North Jason, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Arnoldhaven, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Lake Destiny, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        South Timothyburgh, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        New Jimmyton, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        New Lucasbury, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Cory, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Gileston, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Cindyshire, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        East Michaelfort, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Joybury, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Emmatown, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Colehaven, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Coryton, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Amyborough, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Reynoldsville, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Billy, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Adamburgh, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Wilsonmouth, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        South Kimberly, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Benjaminland, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Zacharyport, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Devonville, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        East Thomas, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        New Jeffrey, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Davidside, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Jamesville, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        New Kelly, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Lake Antonio, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        New Elizabethside, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Millsbury, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Lloydton, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Jeremy, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        New Elizabethtown, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Charlesstad, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Josephbury, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Seanfurt, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Williambury, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        South Jorgeside, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Robertborough, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        South Saratown, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Hullview, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Philipland, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        North Patty, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        North Stephen, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Stevensland, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Reyesstad, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Bellberg, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        North Johnland, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Martinezburgh, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Joshuatown, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        West Ericstad, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Tuckertown, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Perezton, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Lake Abigail, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        Jacobshire, AP\n",
      "      </p>, <p class=\"location\">\n",
      "        Port Susan, AE\n",
      "      </p>, <p class=\"location\">\n",
      "        North Tiffany, AA\n",
      "      </p>, <p class=\"location\">\n",
      "        Michelleville, AP\n",
      "      </p>]\n"
     ]
    }
   ],
   "source": [
    "locations = soup.findAll('p', attrs={'class' : 'location'})\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dd7ffeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>, <time datetime=\"2021-04-08\">2021-04-08</time>]\n"
     ]
    }
   ],
   "source": [
    "posting_dates = soup.findAll('time')\n",
    "print(posting_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "457aba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_cleaned = [companies.text.strip() for companies in companies]\n",
    "locations_cleaned = [locations.text.strip() for locations in locations]\n",
    "posting_dates_cleaned = [posting_dates.text.strip() for posting_dates in posting_dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b6393c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Payne, Roberts and Davis', 'Vasquez-Davidson', 'Jackson, Chambers and Levy', 'Savage-Bradley', 'Ramirez Inc', 'Rogers-Yates', 'Kramer-Klein', 'Meyers-Johnson', 'Hughes-Williams', 'Jones, Williams and Villa', 'Garcia PLC', 'Gregory and Sons', 'Clark, Garcia and Sosa', 'Bush PLC', 'Salazar-Meyers', 'Parker, Murphy and Brooks', 'Cruz-Brown', 'Macdonald-Ferguson', 'Williams, Peterson and Rojas', 'Smith and Sons', 'Moss, Duncan and Allen', 'Gomez-Carroll', 'Manning, Welch and Herring', 'Lee, Gutierrez and Brown', 'Davis, Serrano and Cook', 'Smith LLC', 'Thomas Group', 'Silva-King', 'Pierce-Long', 'Walker-Simpson', 'Cooper and Sons', 'Donovan, Gonzalez and Figueroa', 'Morgan, Butler and Bennett', 'Snyder-Lee', 'Harris PLC', 'Washington PLC', 'Brown, Price and Campbell', 'Mcgee PLC', 'Dixon Inc', 'Thompson, Sheppard and Ward', 'Adams-Brewer', 'Schneider-Brady', 'Gonzales-Frank', 'Smith-Wong', 'Pierce-Herrera', 'Aguilar, Rivera and Quinn', 'Lowe, Barnes and Thomas', 'Lewis, Gonzalez and Vasquez', 'Taylor PLC', 'Oliver, Jones and Ramirez', 'Rivera and Sons', 'Garcia PLC', 'Johnson, Wells and Kramer', 'Gonzalez LLC', 'Morgan, White and Macdonald', 'Robinson-Fitzpatrick', 'Waters, Wilson and Hoover', 'Hill LLC', 'Li-Gregory', 'Fisher, Ryan and Coleman', 'Stewart-Alexander', 'Abbott and Sons', 'Bryant, Santana and Davenport', 'Smith PLC', 'Patterson-Singh', 'Martinez-Berry', 'May, Taylor and Fisher', 'Bailey, Owen and Thompson', 'Vasquez Ltd', 'Leblanc LLC', 'Jackson, Ali and Mckee', 'Blankenship, Knight and Powell', 'Patton, Haynes and Jones', 'Wood Inc', 'Collins Group', 'Flores-Nelson', 'Mitchell, Jones and Olson', 'Howard Group', 'Kramer-Edwards', 'Berry-Houston', 'Mathews Inc', 'Riley-Johnson', 'Spencer and Sons', 'Camacho-Sanchez', 'Oliver and Sons', 'Eaton PLC', 'Stanley-Frederick', 'Bradley LLC', 'Parker, Goodwin and Zavala', 'Kim-Miles', 'Moreno-Rodriguez', 'Brown-Ortiz', 'Hartman PLC', 'Brooks Inc', 'Washington-Castillo', 'Nguyen, Yoder and Petty', 'Holder LLC', 'Yates-Ferguson', 'Ortega-Lawrence', 'Fuentes, Walls and Castro']\n",
      "['Stewartbury, AA', 'Christopherville, AA', 'Port Ericaburgh, AA', 'East Seanview, AP', 'North Jamieview, AP', 'Davidville, AP', 'South Christopher, AE', 'Port Jonathan, AE', 'Osbornetown, AE', 'Scotttown, AP', 'Ericberg, AE', 'Ramireztown, AE', 'Figueroaview, AA', 'Kelseystad, AA', 'Williamsburgh, AE', 'Mitchellburgh, AE', 'West Jessicabury, AA', 'Maloneshire, AE', 'Johnsonton, AA', 'South Davidtown, AP', 'Port Sara, AE', 'Marktown, AA', 'Laurenland, AE', 'Lauraton, AP', 'South Tammyberg, AP', 'North Brandonville, AP', 'Port Robertfurt, AA', 'Burnettbury, AE', 'Herbertside, AA', 'Christopherport, AP', 'West Victor, AE', 'Port Aaron, AP', 'Loribury, AA', 'Angelastad, AP', 'Larrytown, AE', 'West Colin, AP', 'West Stephanie, AP', 'Laurentown, AP', 'Wrightberg, AP', 'Alberttown, AE', 'Brockburgh, AE', 'North Jason, AE', 'Arnoldhaven, AE', 'Lake Destiny, AP', 'South Timothyburgh, AP', 'New Jimmyton, AE', 'New Lucasbury, AP', 'Port Cory, AE', 'Gileston, AA', 'Cindyshire, AA', 'East Michaelfort, AA', 'Joybury, AE', 'Emmatown, AE', 'Colehaven, AP', 'Port Coryton, AE', 'Amyborough, AA', 'Reynoldsville, AA', 'Port Billy, AP', 'Adamburgh, AA', 'Wilsonmouth, AA', 'South Kimberly, AA', 'Benjaminland, AP', 'Zacharyport, AA', 'Port Devonville, AE', 'East Thomas, AE', 'New Jeffrey, AP', 'Davidside, AA', 'Jamesville, AA', 'New Kelly, AP', 'Lake Antonio, AA', 'New Elizabethside, AA', 'Millsbury, AE', 'Lloydton, AP', 'Port Jeremy, AA', 'New Elizabethtown, AA', 'Charlesstad, AE', 'Josephbury, AE', 'Seanfurt, AA', 'Williambury, AA', 'South Jorgeside, AP', 'Robertborough, AP', 'South Saratown, AP', 'Hullview, AA', 'Philipland, AP', 'North Patty, AE', 'North Stephen, AE', 'Stevensland, AP', 'Reyesstad, AE', 'Bellberg, AP', 'North Johnland, AE', 'Martinezburgh, AE', 'Joshuatown, AE', 'West Ericstad, AA', 'Tuckertown, AE', 'Perezton, AE', 'Lake Abigail, AE', 'Jacobshire, AP', 'Port Susan, AE', 'North Tiffany, AA', 'Michelleville, AP']\n",
      "['2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08', '2021-04-08']\n"
     ]
    }
   ],
   "source": [
    "print(companies_cleaned)\n",
    "print(locations_cleaned)\n",
    "print(posting_dates_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b14c1e",
   "metadata": {},
   "source": [
    "d. Take the lists that you have created and combine them into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99d8b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_python_df = pd.DataFrame({\n",
    "    'company': companies_cleaned,\n",
    "    'location': locations_cleaned,\n",
    "    'posting_date': posting_dates_cleaned,\n",
    "    'job title' : jobs\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef27283a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       company              location posting_date  \\\n",
      "0     Payne, Roberts and Davis       Stewartbury, AA   2021-04-08   \n",
      "1             Vasquez-Davidson  Christopherville, AA   2021-04-08   \n",
      "2   Jackson, Chambers and Levy   Port Ericaburgh, AA   2021-04-08   \n",
      "3               Savage-Bradley     East Seanview, AP   2021-04-08   \n",
      "4                  Ramirez Inc   North Jamieview, AP   2021-04-08   \n",
      "..                         ...                   ...          ...   \n",
      "95     Nguyen, Yoder and Petty      Lake Abigail, AE   2021-04-08   \n",
      "96                  Holder LLC        Jacobshire, AP   2021-04-08   \n",
      "97              Yates-Ferguson        Port Susan, AE   2021-04-08   \n",
      "98             Ortega-Lawrence     North Tiffany, AA   2021-04-08   \n",
      "99   Fuentes, Walls and Castro     Michelleville, AP   2021-04-08   \n",
      "\n",
      "                             job title  \n",
      "0              Senior Python Developer  \n",
      "1                      Energy engineer  \n",
      "2                      Legal executive  \n",
      "3               Fitness centre manager  \n",
      "4                      Product manager  \n",
      "..                                 ...  \n",
      "95  Museum/gallery exhibitions officer  \n",
      "96            Radiographer, diagnostic  \n",
      "97              Database administrator  \n",
      "98                  Furniture designer  \n",
      "99                         Ship broker  \n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(fake_python_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6793ad01",
   "metadata": {},
   "source": [
    "2. Next, add a column that contains the url for the \"Apply\" button. Try this in two ways.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea71598",
   "metadata": {},
   "source": [
    "  a. First, use the BeautifulSoup find_all method to extract the urls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "442efc2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/energy-engineer-1.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/legal-executive-2.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/fitness-centre-manager-3.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/product-manager-4.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/medical-technical-officer-5.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/physiological-scientist-6.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/textile-designer-7.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/waste-management-officer-9.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/software-engineer-python-10.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/interpreter-11.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/architect-12.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/meteorologist-13.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/audiological-scientist-14.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/english-as-a-second-language-teacher-15.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/surgeon-16.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/equities-trader-17.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/newspaper-journalist-18.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/materials-engineer-19.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-20.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/product-process-development-scientist-21.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/scientist-research-maths-22.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/ecologist-23.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/materials-engineer-24.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/historic-buildings-inspector-conservation-officer-25.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/data-scientist-26.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/psychiatrist-27.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/structural-engineer-28.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/immigration-officer-29.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-30.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/neurosurgeon-31.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/broadcast-engineer-32.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/make-33.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/nurse-adult-34.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/air-broker-35.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/editor-film-video-36.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/production-assistant-radio-37.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/engineer-communications-38.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/sales-executive-39.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-40.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/futures-trader-41.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/tour-manager-42.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/cytogeneticist-43.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/designer-multimedia-44.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/trade-union-research-officer-45.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/chemist-analytical-46.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/programmer-multimedia-47.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/engineer-broadcasting-operations-48.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/teacher-primary-school-49.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/python-developer-50.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/manufacturing-systems-engineer-51.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/producer-television-film-video-52.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/scientist-forensic-53.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/bonds-trader-54.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/editorial-assistant-55.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/photographer-56.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/retail-banker-57.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/jewellery-designer-58.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/ophthalmologist-59.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-60.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/licensed-conveyancer-61.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/futures-trader-62.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/counselling-psychologist-63.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/insurance-underwriter-64.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/engineer-automotive-65.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/producer-radio-66.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/dispensing-optician-67.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/designer-fashion-clothing-68.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/chartered-loss-adjuster-69.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/back-end-web-developer-python-django-70.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/forest-woodland-manager-71.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/clinical-cytogeneticist-72.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/print-production-planner-73.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/systems-developer-74.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/graphic-designer-75.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/writer-76.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/field-seismologist-77.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/chief-strategy-officer-78.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/air-cabin-crew-79.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/python-programmer-entry-level-80.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/warden-ranger-81.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/sports-therapist-82.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/arts-development-officer-83.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/printmaker-84.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/health-and-safety-adviser-85.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/manufacturing-systems-engineer-86.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/programmer-applications-87.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/medical-physicist-88.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/media-planner-89.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/software-developer-python-90.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/surveyor-land-geomatics-91.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/legal-executive-92.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/librarian-academic-93.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/barrister-94.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/museum-gallery-exhibitions-officer-95.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/radiographer-diagnostic-96.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/database-administrator-97.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/furniture-designer-98.html', 'https://www.realpython.com', 'https://realpython.github.io/fake-jobs/jobs/ship-broker-99.html']\n"
     ]
    }
   ],
   "source": [
    "urls = [apply.get('href') for apply in soup.findAll('a')]\n",
    "print(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16b1b1",
   "metadata": {},
   "source": [
    "  b. Next, get those same urls in a different way. Examine the urls and see if you can spot the pattern of how they are constructed. Then, build the url using the elements you have already extracted. Ensure that the urls that you created match those that you extracted using BeautifulSoup. Warning: You will need to do some string cleaning and prep in constructing the urls this way. For example, look carefully at the urls for the \"Software Engineer (Python)\" job and the \"Scientist, research (maths)\" job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223dfb2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
